Introduction to distance sampling
========================================================
author: David L Miller 
date: 
transition: rotate
css: custom.css

Counting animals
========================================================

```{r setup, include=FALSE}
library(knitr)
opts_chunk$set(cache=TRUE, echo=FALSE)
# load the sperm whale data
load("../spermwhale-analysis/df-models.RData")
# remove the fitted models to avoid confusion
rm(df_hr, df_hr_ss)
```

- Counting animals is hard
- Limited resources
- 

Overview
====================

Here we'll look at:

- Quadrats to line transects
- Simple estimates of abundance
- Why is detectability important?
- What is a detection function?
- Horvitz-Thompson estimators


How many animals are there? (500!)
========================================================


```{r, plot}
# code adapted from my RDistance book, converged.yt/RDistanceBook
set.seed(1234) # same results every time
library(mgcv) # for inSide

N <- 500
# generate population locations
x <- runif(N)
y <- runif(N)
# plot it
par(mar=rep(0,4))
plot(x,y, pch=19,asp=1,cex=0.4,main="",col="grey", axes=FALSE, xlab="", ylab="")
polygon(x=c(0,1,1,0,0), y=c(0,0,1,1,0))
```

General strategy
========================================================

- Take a sample in some fixed areas
- Find density/abundance in *covered area*
- Multiply up to get abundance

General strategy (What did we assume?)
========================================================

- Take a sample in some fixed areas
  - *Sample is representative*
- Find density/abundance in *covered area*
  - *Estimator is "good"*
- Multiply up to get abundance
  - *Uniform distribution outside covered area*

Plot sampling
========================================================

```{r, plotsampling}
par(mar=rep(0,4))
plot(x,y, pch=19,asp=1,cex=0.4,main="",col="grey", axes=FALSE, xlab="", ylab="")
polygon(x=c(0,1,1,0,0), y=c(0,0,1,1,0))

# generate some quadrats
set.seed(3111)# same results every time
quadrat <- list(x=c(0,0,0.1,0.1,0),y=c(0,0.1,0.1,0,0))
n <- 0
for(i in 1:10){
  # randomly place a quadrat (and plot it)
  this.quadrat <- quadrat
  this.quadrat$x <- this.quadrat$x + runif(1, 0.1, 0.9)
  this.quadrat$y <- this.quadrat$y + runif(1, 0.1, 0.9)
  polygon(this.quadrat, lty=2, border="blue")
  # see which points are inside
  inout <- inSide(this.quadrat, x, y)
  # count them
  n <- n + sum(inout)
  # plot the points inside the quadrat in red
  points(x[inout], y[inout], pch=19, cex=0.4, col="red")
}
```


Plot sampling (maths)
========================================================

- Surveyed 10 quadrats (each $0.1^2$ units)
  - Total covered area $a=10 * 0.1^2 =$ `r 10*0.1^2`
- Saw $n=$ `r n` animals
- Estimated density $\hat{D}=n/a=$ `r n/(10*0.1^2)`
- Total area $A=1$
- Estimated abundance $\hat{N}=$ `r  n/(10*0.1^2)`



Strip transect
========================================================

```{r strip}
par(mar=rep(0,4))
plot(x,y, pch=19,asp=1,cex=0.4,main="",col="grey", axes=FALSE, xlab="", ylab="")
polygon(x=c(0,1,1,0,0), y=c(0,0,1,1,0))

# zero the count from last time
n <- 0

# generate some strips
set.seed(12)
# in this case we don't randomise the offset of the grid
strip <- list(x=c(-0.0125,-0.0125,0.0125,0.0125,-0.0125), y=c(0,1,1,0,0))
strip$x <- strip$x + 0.1
for(i in 1:4){
  # plot the strip and its centreline
  polygon(strip, lty=2, border="blue")
  lines(rep(mean(range(strip$x)),2), c(0,1), col="blue")
  # see what was inside the strip
  inout <- inSide(strip,x,y)
  # count them
  n <- n + sum(inout)
  # plot those animals within the strip
  points(x[inout], y[inout], pch=19, cex=0.4, col="red")
  # calculate next strip location
  strip$x <- strip$x+0.2
}
# covered area -- same area as for the quadrats
covered <- 4*1*0.025
# estimate density
D <- n/covered
# area of the survey region
A <- 1
# estimate abundance
Nhat <- D*A
```


Strip transect (maths)
========================================================

- Surveyed 4 lines (each $1*0.025$ units)
  - Total covered area $a=4*1*0.025 =$ `r covered`
- Saw $n=$ `r n` animals
- Estimated density $\hat{D}=n/a=$ `r D`
- Total area $A=1$
- Estimated abundance $\hat{N}=$ `r  Nhat`


Detectability
====================================
type: section


Detectability matters!
====================================

- We've assumed certain detection so far
- This rarely happens IRL
- Distance to the line is important
  - (Other things too, more on that later)
  - Detectability should decrease with increasing distance

Detection as a function of distance
====================================

```{r df}
curve(exp(-x^2/(2*0.01^2)), from=0, to=0.025, xlab="Distance", ylab="Probability of detection")
```

Recording distances is more efficient
======================================

- Plots: what if an animal is *just* outside the box?
- Strips: what if an animal is *just* outside the strip?

- Line transects: record **everything** then discard later
- *Truncation distance* can be decided later

Line transect
========================================================


```{r lt}
par(mar=rep(0,4))
plot(x,y, pch=19,asp=1,cex=0.4,main="",col="grey", axes=FALSE, xlab="", ylab="")
polygon(x=c(0,1,1,0,0), y=c(0,0,1,1,0))

# generate some lines
# in this case we don't randomise the offset of the grid
lt <- list(x=c(-0.0125, -0.0125, 0.0125, 0.0125, -0.0125),  y=c(0, 1, 1, 0, 0))
# set sigma
sigma <- 0.01
# storage for detected distances
detected_distances <- c()
for(i in 1:4){
  # calculate next strip location
  lt$x <- lt$x+0.15
  # plot the line transect
  lines(x=rep(mean(range(lt$x)),2), y=c(0,1), col="blue",lty=2)
  # calculate the distances to animals from the line
  distances <- abs(lt$x - x)
  # randomly decide which were detected
  detected <- exp(-distances^2/(2*sigma^2)) > runif(length(distances))
  # plot those animals detected
  points(x[detected], y[detected], pch=19, cex=0.4, col="red")
  # collect the distances to detected objects
  detected_distances <- c(detected_distances, distances[detected])
}
```


Line transects - distances
========================================================

- Now we recorded distances, what do they look like?
- Drop-off in # observations w. increasing distance

```{r distance-hist}
hist(detected_distances, main="", xlab="Distance",breaks=seq(0,max(detected_distances),len=7))
```

"You should model that"
====================================
type: section

Detection function
====================================

```{r df-fit}
hist(detected_distances, main="", xlab="Distance",breaks=seq(0,max(detected_distances),len=7), freq=FALSE, ylim=c(0, 85))
xx <- seq(0, 0.05, len=1000)
lines(xx, exp(-xx^2/(2*sigma^2))/integrate(function(x)  exp(-x^2/(2*sigma^2)), lower=0, upper=0.02)$value)
```


Line transects - general idea
========================================================

- Calculate *average detection probability* using detection function
- $\hat{p} = \int_0^w \frac{1}{w} g(x; \hat{\theta}) dx$
- $\frac{1}{w}$ tells us about assumed density wrt line
  - *uniform* from the line

```{r pi-y}
par(mfrow=c(1,3))
curve(exp(-x^2/(2*0.01^2)), from=0, to=0.025, xlab="Distance", ylab="Probability of detection")
plot(seq(0,0.025, len=2), rep(1/0.25,2), type="l", xlab="Distance", ylab="Density wrt line", ylim=c(0, 1/0.25))
curve(exp(-x^2/(2*0.01^2))/0.025, from=0, to=0.025, xlab="Distance", ylab="Probability of detection")
```

Line transects - distances
========================================================

- Model drop-off using a *detection function*
- Use extra information estimate $\hat{N}$
- How far was the truncation?
- Effective strip width $\hat{\mu}=w\hat{p}$


Line transect (maths)
========================================================

```{r calc-Nhat-line}
## calculate Nhat
# calculate mu, since we know sigma and set w=0.02
mu <- integrate(function(x)  exp(-x^2/(2*sigma^2)), lower=0, upper=0.02)$value
# calculate p = mu/w
p <- mu/0.02
n<-length(detected_distances)
covered <- 2*0.02*5
Nhat.lt <- A*n/(covered*p)
```


- Surveyed 5 lines (each $1*0.025$ units)
  - Total covered area $a=5*1*0.02 =$ `r covered`
- Probability of detection $\hat{p} = \int_0^w \frac{g(x)}{w}dx=$ `r round(p,4)`
  - Total *effective* covered area $a\hat{p}=$ `r covered` $*$ `r round(p,4)` $=$ `r round(covered*p,4)`
- Saw $n=$ `r n` animals
- Estimated density $\hat{D}=n/(a\hat{p})=$ `r round(n/(covered*p), 0)`
- Total area $A=1$
- Estimated abundance $\hat{N}=$ `r  round(Nhat.lt, 0)`

Summary
=============

Line transects:

- Efficient survey design
- Relaxed the assumption of perfect detection
- More information = better inference

Line transect assumptions
==========================

1. Animals are distributed independent of lines
2. On the line, detection is certain
3. Distances are recoreded correctly
4. Animals don't move before detection


Detection functions
====================================
type: section


What are detection functions?
========================================================

- Model $\mathbb{P}\left( \text{detection } \vert \text{ animal at distance } x \right)$
- (Hence the integration)
- Many different forms, depending on the data
- All share some characteristics


Detection function assumptions
================================

- Have a "shoulder"
  - *we see things nearby easily*
- Monotonic decreasing
  - *never increasing with increasing distance*
- "Model robust"
  - *lots of forms/flexible models*
- "Pooling robust"
  - *individual heterogeneity averages out*
- "Efficient"
  - *models don't need lots of parameters*


Possible detection functions
=============================

- There are many options
- A restricted set we'll cover in this course...
  - Half-normal
  - Hazard-rate
  - adjustments to the above

Half-normal detection functions
================================

```{r df-hn}
curve(exp(-x^2/(2*0.01^2)), from=0, to=0.025, xlab="Distance", ylab="Probability of detection")
```


Hazard-rate detection functions
================================

```{r df-hr}
curve(1-exp(-(x/0.005)^(-2.5)), from=0, to=0.025, xlab="Distance", ylab="Probability of detection")
```

Adjustment terms
==================

- These models are flexible
- What about adding more flexibilty by "adjusting" them
- Options:
  - Cosine series
  - Polynomials
  - Hermite polynomials
- Add extra flexibility


Okay, but how can we actually do this?
===========================================
type: section

Modelling strategy
=============================

- Pick some formulations, fit models
- Evaluate if they violate the assumptions
- Check models
- Select models
- Estimate $\hat{N}$


Fitting detection functions (in R!)
============================

- Using the package `Distance`
- Need to have data setup a certain way
  - At least columns called `object`, `distance`

```{r echo=TRUE}
library(Distance)
df_hn <- ds(distdata, truncation=6000, adjustment = NULL)
```

Model summary
================

```{r echo=TRUE}
summary(df_hn)
```

Plotting models
================

```{r echo=TRUE}
plot(df_hn)
```


Model checking
=================

```{r echo=TRUE, results="hide"}
ddf.gof(df_hn$ddf)
```

Model checking
=================

- As well as quantile-quantile plot, tests
- Kolmogorov-Smirnov: largest distance on Q-Q plot
- Cramer-von Mises: tests sum of distances



Model checking
=================
- blue line is Kolmogorov-Smirnov test statistic
- red lines is calculation of Cramer-von Mises statistic

```{r }
# adapted from my RDistanceBook
qq <- ddf.gof(df_hn$ddf)
gof_tests_statplot <- function(model){
  cdf_values <- ddf.gof(df_hn$ddf, qq=FALSE)$dsgof$cdf

  # calculate EDF values
  edf_values <- ddf.gof(df_hn$ddf, qq=FALSE)$dsgof$edf

  # plot Cramer-von Mises distances
  Map(function(edf, cdf){
        lines(x=rep(edf,2), y=c(edf, cdf), lwd=1.5, col="red")
      },
      edf_values, cdf_values)

  # find & plot which line-point distance is the test statistic for K-S test
  ks.ind <- which.max(abs(cdf_values-edf_values))
  lines(x=rep(edf_values[ks.ind],2), y=c(edf_values[ks.ind], cdf_values[ks.ind]), lwd=1.5, col="blue")

  invisible()
}
gof_tests_statplot(hr.df)
```



Model selection
=================

- Throw out models with bad check results
- Use AIC for model selection

Estimating abundance
===========================================
type: section


Estimating abundance
=======================

- As before, assume density same in sampled/unsampled area
- Horvitz-Thompson estimator

<div class="bigq">
$$
\hat{N} = \frac{A}{a} \sum_{i=1}^n \frac{1}{\hat{p_i}}
$$
</div>


Estimating uncertainty
===========================================
type: section


Sources of uncertainty
=======================

<div class="bigq">
$$
\hat{N} = \frac{A}{a} \sum_{i=1}^\color{blue}{n} \frac{1}{\color{red}{\hat{p_i}}}
$$
</div>

- Uncertainty in $n$ is from <span style="color:blue">sampling</span>
- Uncertainty in $\hat{p}$ is from the <span style="color:red">model</span>


Uncertainty from sampling
============================

- Usually calculate *encounter rate* variance $n/L$


Uncertainty from the model
============================

- Model uncertainty from parameters ($\boldsymbol{\hat{\theta}}$)
- $\hat{p}$

Putting those parts together
================================

<div style="font-size:150%">
$$
\text{CV}\left( \hat{D} \right) = \text{CV}\left( \frac{n}{L} \right) + \text{CV}\left( \hat{p}\right)
$$
</div>


Covariates
===========================================
type: section



